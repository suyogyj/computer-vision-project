{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from mmseg.apis import inference_model, init_model\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set paths for your dataset\n",
    "base_dir = \"mmsegmentation/data/loveDA\"\n",
    "img_dir = os.path.join(base_dir, \"img_dir/train\")\n",
    "ann_dir = os.path.join(base_dir, \"ann_dir/train\")\n",
    "\n",
    "# Output paths\n",
    "train_initial_img_dir = os.path.join(base_dir, \"img_dir/train_initial\")\n",
    "train_pool_img_dir = os.path.join(base_dir, \"img_dir/train_pool\")\n",
    "train_initial_ann_dir = os.path.join(base_dir, \"ann_dir/train_initial\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_initial_img_dir, exist_ok=True)\n",
    "os.makedirs(train_pool_img_dir, exist_ok=True)\n",
    "os.makedirs(train_initial_ann_dir, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "initial_subset_size = 50  # Number of images to include in the initial labeled set\n",
    "\n",
    "# List all image files in the training directory\n",
    "all_images = [f for f in os.listdir(img_dir) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Split into initial labeled set and unlabeled pool\n",
    "initial_images = all_images[:initial_subset_size]\n",
    "pool_images = all_images[initial_subset_size:]\n",
    "\n",
    "# Copy files to their respective directories\n",
    "for img_file in initial_images:\n",
    "    # Copy image to train_initial\n",
    "    shutil.copy(os.path.join(img_dir, img_file), os.path.join(train_initial_img_dir, img_file))\n",
    "\n",
    "    # Copy corresponding annotation to train_initial\n",
    "    ann_file = img_file.replace('.jpg', '.png').replace('.png', '_label.png')  # Adjust extension if needed\n",
    "    ann_path = os.path.join(ann_dir, ann_file)\n",
    "    if os.path.exists(ann_path):\n",
    "        shutil.copy(ann_path, os.path.join(train_initial_ann_dir, ann_file))\n",
    "\n",
    "for img_file in pool_images:\n",
    "    # Copy image to train_pool\n",
    "    shutil.copy(os.path.join(img_dir, img_file), os.path.join(train_pool_img_dir, img_file))\n",
    "\n",
    "print(\"Dataset split completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: mmsegmentation/work_dirs/deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512/iter_16000.pth\n"
     ]
    }
   ],
   "source": [
    "config_file = 'mmsegmentation/configs/deeplabv3plus/deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512_active.py'\n",
    "checkpoint_file = 'mmsegmentation/work_dirs/deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512/iter_8000_active.pth'  # Adjust if needed\n",
    "model = init_model(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dir = 'mmsegmentation/data/loveDA/img_dir/train_pool'\n",
    "unlabeled_images = [os.path.join(unlabeled_dir, f) for f in os.listdir(unlabeled_dir) if f.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2472/2472 [12:27<00:00,  3.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "uncertainties = []\n",
    "\n",
    "for img_path in tqdm(unlabeled_images):\n",
    "    # Perform inference\n",
    "    result = inference_model(model, img_path)\n",
    "    \n",
    "    # Extract the logits from the `SegDataSample` object\n",
    "    logits = result.seg_logits.data  # Access the logits tensor\n",
    "    \n",
    "    # Convert logits to probabilities\n",
    "    probs = torch.softmax(logits, dim=0).cpu().numpy()\n",
    "    \n",
    "    # Compute pixel-wise entropy and average over the image\n",
    "    entropy = -np.sum(probs * np.log(probs + 1e-10), axis=0).mean()  # Compute average entropy\n",
    "    uncertainties.append((img_path, entropy))\n",
    "\n",
    "# Sort images by uncertainty (descending order)\n",
    "uncertainties.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the uncertainties\n",
    "\n",
    "with open('uncertainties.txt', 'w') as f:\n",
    "    for item in uncertainties:\n",
    "        f.write(\"%s\\n\" % str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir_pool = 'mmsegmentation/data/loveDA/img_dir/train_pool'\n",
    "ann_dir_pool = 'mmsegmentation/data/loveDA/ann_dir/train'\n",
    "img_dir_initial = 'mmsegmentation/data/loveDA/img_dir/train_initial'\n",
    "ann_dir_initial = 'mmsegmentation/data/loveDA/ann_dir/train_initial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mmsegmentation/data/loveDA/ann_dir/train\\\\1931.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\shutil.py:791\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 791\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'mmsegmentation/data/loveDA/ann_dir/train\\\\1931.png' -> 'mmsegmentation/data/loveDA/ann_dir/train_initial\\\\1931.png'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m     ann_name \u001b[38;5;241m=\u001b[39m img_name  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Move image\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# shutil.move(os.path.join(img_dir_pool, img_name), os.path.join(img_dir_initial, img_name))\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Move annotation\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_dir_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mann_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_dir_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mann_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# ann_path = os.path.join(ann_dir_pool, ann_name)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# if os.path.exists(ann_path):\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#     shutil.move(ann_path, os.path.join(ann_dir_initial, ann_name))\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(selected_images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images and annotations to the labeled set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\shutil.py:811\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    809\u001b[0m         rmtree(src)\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 811\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\shutil.py:435\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    434\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 435\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\shutil.py:264\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc, \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[0;32m    267\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mmsegmentation/data/loveDA/ann_dir/train\\\\1931.png'"
     ]
    }
   ],
   "source": [
    "selected_images = [x[0] for x in uncertainties[:40]]\n",
    "for img_path in selected_images:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    ann_name = img_name  # Adjust as needed\n",
    "    \n",
    "    # Move image\n",
    "    # shutil.move(os.path.join(img_dir_pool, img_name), os.path.join(img_dir_initial, img_name))\n",
    "    \n",
    "    # Move annotation\n",
    "    shutil.move(os.path.join(ann_dir_pool, ann_name), os.path.join(ann_dir_initial, ann_name))\n",
    "    # ann_path = os.path.join(ann_dir_pool, ann_name)\n",
    "    # if os.path.exists(ann_path):\n",
    "    #     shutil.move(ann_path, os.path.join(ann_dir_initial, ann_name))\n",
    "\n",
    "print(f\"Moved {len(selected_images)} images and annotations to the labeled set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 12:03:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 295596494\n",
      "    GPU 0: NVIDIA GeForce GTX 1650 Ti\n",
      "    CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6\n",
      "    NVCC: Cuda compilation tools, release 12.6, V12.6.85\n",
      "    MSVC: Microsoft (R) C/C++ Optimizing Compiler Version 19.29.30143 for x64\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.0.1+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 193431937\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu118\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.5\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 295596494\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "12/12 12:03:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    test=dict(\n",
      "        ann_dir='ann_dir/val',\n",
      "        data_root='mmsegmentation/loveDA/',\n",
      "        img_dir='img_dir/test',\n",
      "        split=None,\n",
      "        type='LoveDADataset'),\n",
      "    train=dict(\n",
      "        ann_dir='ann_dir/train_initial',\n",
      "        data_root='mmsegmentation/loveDA/',\n",
      "        img_dir='img_dir/train_initial',\n",
      "        split=None,\n",
      "        type='LoveDADataset'),\n",
      "    val=dict(\n",
      "        ann_dir='ann_dir/val',\n",
      "        data_root='mmsegmentaion/loveDA/',\n",
      "        img_dir='img_dir/val',\n",
      "        split=None,\n",
      "        type='LoveDADataset'),\n",
      "    workers_per_gpu=2)\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/loveDA'\n",
      "dataset_type = 'LoveDADataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=8000, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "launcher = 'none'\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=64,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=256,\n",
      "        in_index=2,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=7,\n",
      "        num_convs=1,\n",
      "        type='FCNHead'),\n",
      "    backbone=dict(\n",
      "        contract_dilation=True,\n",
      "        depth=18,\n",
      "        dilations=(\n",
      "            1,\n",
      "            1,\n",
      "            2,\n",
      "            4,\n",
      "        ),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        norm_eval=False,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        strides=(\n",
      "            1,\n",
      "            2,\n",
      "            1,\n",
      "            1,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNetV1c'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        c1_channels=12,\n",
      "        c1_in_channels=64,\n",
      "        channels=128,\n",
      "        dilations=(\n",
      "            1,\n",
      "            12,\n",
      "            24,\n",
      "            36,\n",
      "        ),\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=512,\n",
      "        in_index=3,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=7,\n",
      "        type='DepthwiseSeparableASPPHead'),\n",
      "    pretrained='open-mmlab://resnet18_v1c',\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=None,\n",
      "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=80000,\n",
      "        eta_min=0.0001,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/loveDA',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='LoveDADataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=80000, type='IterBasedTrainLoop', val_interval=8000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='img_dir/train', seg_map_path='ann_dir/train'),\n",
      "        data_root='data/loveDA',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='LoveDADataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='data/loveDA',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='LoveDADataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512_active'\n",
      "\n",
      "12/12 12:03:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/12 12:03:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "12/12 12:03:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "12/12 12:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet18_v1c\n",
      "12/12 12:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet18_v1c\n",
      "12/12 12:03:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "12/12 12:03:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "12/12 12:03:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "12/12 12:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\mmsegmentation\\work_dirs\\deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512_active.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\suyog\\desktop\\monsoon_24\\cv\\computer-vision-project\\mmsegmentation\\mmseg\\models\\backbones\\resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "c:\\users\\suyog\\desktop\\monsoon_24\\cv\\computer-vision-project\\mmsegmentation\\mmseg\\models\\losses\\cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n",
      "c:\\users\\suyog\\desktop\\monsoon_24\\cv\\computer-vision-project\\mmsegmentation\\mmseg\\engine\\hooks\\visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n",
      "c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\users\\suyog\\desktop\\monsoon_24\\cv\\computer-vision-project\\mmsegmentation\\mmseg\\datasets\\transforms\\loading.py:84: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n",
      "c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/train.py\", line 104, in <module>\n",
      "    main()\n",
      "  File \"tools/train.py\", line 100, in main\n",
      "    runner.train()\n",
      "  File \"c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\mmengine\\runner\\runner.py\", line 1777, in train\n",
      "    model = self.train_loop.run()  # type: ignore\n",
      "  File \"c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\mmengine\\runner\\loops.py\", line 289, in run\n",
      "    self.run_iter(data_batch)\n",
      "  File \"c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\mmengine\\runner\\loops.py\", line 316, in run_iter\n",
      "    self.runner.call_hook(\n",
      "  File \"c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\mmengine\\runner\\runner.py\", line 1839, in call_hook\n",
      "    getattr(hook, fn_name)(self, **kwargs)\n",
      "  File \"c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\mmengine\\hooks\\runtime_info_hook.py\", line 126, in after_train_iter\n",
      "    runner.message_hub.update_scalar(f'train/{key}', value)\n",
      "  File \"c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\mmengine\\logging\\message_hub.py\", line 132, in update_scalar\n",
      "    checked_value = self._get_valid_value(value)\n",
      "  File \"c:\\Users\\suyog\\Desktop\\monsoon_24\\CV\\computer-vision-project\\.venv\\lib\\site-packages\\mmengine\\logging\\message_hub.py\", line 346, in _get_valid_value\n",
      "    value = value.item()\n",
      "RuntimeError: CUDA error: an illegal memory access was encountered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %cd mmsegmentation\n",
    "!python tools/train.py configs/deeplabv3plus/deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512_active.py --work-dir work_dirs/deeplabv3plus_r18-d8_4xb4-80k_loveda-512x512_active --resume -\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
